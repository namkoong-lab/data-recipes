{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMAC Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTALLATION NOTES**\n",
    "  - SMAC seems to be incompatible with the latest version of numpy. Use numpy 1.26.4 instead `pip install numpy==1.26.4`\n",
    "  - SMAC needs `swig` to be installed on your machine to be installable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demos dataset mixture tuning using SMAC3.\n",
    "  - We have 8 datasets, each comprising 10,000 rows, from which we must select a 10,000-row training set\n",
    "  - We use Bayesian Optimization to figure out the best number of rows to select from each of the 8 datasets to form our final 10,000-row training set\n",
    "\n",
    "Some details\n",
    "  - The datasets have two dependent variables (`X` and `Y`) and one independent variable (`Z`)\n",
    "  - There are 8 datasets - `A`-`D` are the \"good\" ones, `E`-`H` are \"bad\" ones. Dataset `I` is a validation set. See `data_generation.py` for details on how they are generated.\n",
    "  - For simplicity, the model we're training to predict `Z` based on `X` and `Y` is a random forest with a maximum tree depth of 6.\n",
    "      * The `train` function below accepts a set of 8 weights $w_A$ through $w_H$ (between 0 and 100 - SMAC doesnâ€™t seem to allow a constraint that forces parameters to sum to 1), normalizes them to sum to 1 as follows $w_i / \\sum_j w_j$ (maybe use softmax in the future?), and then samples from each of the 8 datasets according to those proportions.\n",
    "      * It then fits a random forest with trees of depth 6 to that sampled dataset and checks its performance on the validation set `I`.\n",
    "      * The function also accepts a \"budget\" which is the number of trees in the forest. When we do this with a NN, this will be the computational budget/number of epochs/whatever\n",
    "  - We then use SMAC3 to perform Bayesian optimization over these 8 weights. We use multi-fidelity optimization, which means that each combination of weights is first trained with a very low budget, bad combinations are quickly eliminated and only promising combinations of weights are trained further. Hyperband is used for this.\n",
    "\n",
    "The plots at the bottom of the notebook show the progress of the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DOs AND QUESTIONS**\n",
    "  - Investigate the best way to optimize over weights that sum to 1\n",
    "  - One way to do multi-fidelity optimization would be to start training all parameter combinations in parallel, and then *abort* any non-promising parameter combinations. As far as I can tell, SMAC doesn't have a mechanism to do this - instead, it begins by calling all parameter combinations with a low budget. It then looks at the results, picks the most promising combinations, and calls `train` again with a larger budget. The problem is that if `train` is implemented naively, it'll just \"repeat\" the lower-budget work every time it's called with a bigger budget (eg: if it's called with a budget of 5, it'll fit 5 trees, and then if it's fit with a budget of 8, it'll repeat the first 5 trees before building the next 3). In this code, I avoided this by saving all intermediate models in memory in a global variable. When the function is called again with the same parameters but a bigger budget, it tries to load the partially trained model before \"continuing\" to train it. For an NN, I imagine we'll have to save this to disk.\n",
    "  - If you look at the plot tracing the cource of optimization, you will notice SMAC is running multiple rounds of Hyperband. I'm not sure this is optimal - a better approach might be to run a single round of Hyperband with many more starting combinations.\n",
    "  - I'm confused by the way SMAC chooses new parameter combinations at the start of every Hyperband bracket. According to the paper, it's supposed to use a random forest trained on all high-budget runs that have completed, but it looks like it keeps on testing some very poor parameter combinations in later steps, so I want to investigate this further. I'm an hour or three into looking at the source code for the package to figure out what's going on - more to come hopefully.\n",
    "  - I've tried to set seeds everywhere I could find them, but there still seems to be some randomness in this algo - it gives a different optimization path every time you run it. Hopefully I'll figure this out down the road.\n",
    "  - There are a few things that the package/Hyperband *cannot* do that we might want to investigate\n",
    "      * The only assumption it makes about the training process is that the loss will eventually converge to some final number as the budget goes to infinity. It doesn't make any assumptions about *how fast* that loss will decrease. If we can use some past scaling laws to put some prior on that convergence, we could abort \"bad\" parameter combinations far quicker\n",
    "      * It makes zero parametric assumptions about the way our dataset weights affect the final loss (i.e., it uses a nonparametric model of the objective function). If our initial investigations seem to indicate there is some clear pattern, we might want to use something parametric here instead.\n",
    "\n",
    "For all the reasons above, I'm wondering whether we should just forget about SMAC and implement this ourselves directly, but we can discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_generation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble as sk_e\n",
    "import sklearn.metrics as sk_m\n",
    "\n",
    "import smac\n",
    "import ConfigSpace\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_generation.generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['A'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store models in memory as they are trained; see\n",
    "# doctstring for train() for an explanation. IRL, we'd need to save this\n",
    "# to disk presumably\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, seed, budget):\n",
    "    '''\n",
    "    This function takes a parameter combination from the SMAC3 optimizer, trains a\n",
    "    model with it, and returns the model's performance from the validation set I.\n",
    "\n",
    "    It accepts the following arguments:\n",
    "      - config : a configuration object containing wA-wH, each numbers in [0, 100].\n",
    "                 We normalize the numbers to sum to 1 to figure out the weight of\n",
    "                 each dataset in our training sample\n",
    "      - seed : the random seed to use\n",
    "      - budget : the number of trees to use in the random forest. If this configuration\n",
    "                 has been trained before with a lower budget, we retrieve that lower-\n",
    "                 budget trained model from the trained_models dictionary and pick up\n",
    "                 from where we left off to save time.\n",
    "    '''\n",
    "\n",
    "    # Normalize the wA-wH variables in our configuration\n",
    "    # --------------------------------------------------\n",
    "    weights = {i : config.get(f'w{i}') for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']}\n",
    "    weights = {i : weights[i] / sum(weights.values()) for i in weights}\n",
    "\n",
    "    # Check whether we already have a trained model\n",
    "    # ---------------------------------------------\n",
    "    serialized_config = str(sorted([f'{k}:{round(v, 5)}' for k, v in weights.items()]))\n",
    "    global trained_models\n",
    "\n",
    "    # Retrieve our previous trained model or create a new one and put it in the dict;\n",
    "    # warm_start = True is needed to make sure we can pick up from where we left off next time\n",
    "    # we use this model\n",
    "    trained_models[serialized_config] = trained_models.get(serialized_config,\n",
    "                                                           sk_e.RandomForestRegressor(n_estimators=0, random_state=seed, max_depth=6, warm_start=True))\n",
    "    m = trained_models[serialized_config]\n",
    "    \n",
    "    # If the model has been trained before, we should only be seeing it again with a\n",
    "    # higher budget (if the model was just created it'll have been created with a budget\n",
    "    # of 0, so this will be true)\n",
    "    assert int(budget) >= m.n_estimators\n",
    "    \n",
    "    # Set the budget\n",
    "    m.n_estimators = int(budget)\n",
    "    \n",
    "    # Get the data we're training on\n",
    "    # ------------------------------\n",
    "    this_data = []\n",
    "    for ds in weights:\n",
    "        this_data.append(data[ds].sample(int(len(data[ds])*weights[ds]), random_state=seed))\n",
    "    this_data = pd.concat(this_data)\n",
    "\n",
    "    # Train\n",
    "    # -----\n",
    "    m.fit(X=this_data[['X', 'Y']], y=this_data['Z'])\n",
    "    \n",
    "    # Return the performance on the eval set (I)\n",
    "    # ------------------------------------------\n",
    "    return(sk_m.mean_squared_error(data['I']['Z'], m.predict(data['I'][['X', 'Y']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the best and worse MSEs\n",
    "best_mse  = train({'wA':1, 'wB':1, 'wC':1, 'wD':1, 'wE':0, 'wF':0, 'wG':0, 'wH':0}, seed=123, budget=30)\n",
    "worst_mse = train({'wA':0, 'wB':0, 'wC':0, 'wD':0, 'wE':1, 'wF':1, 'wG':1, 'wH':1}, seed=123, budget=30)\n",
    "\n",
    "# Clear the saved models\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a configuration space, describing all the values, and the values they can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ConfigSpace.ConfigurationSpace()\n",
    "\n",
    "for ds in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:\n",
    "    cs.add_hyperparameter(ConfigSpace.Float(f'w{ds}', [0, 100]))\n",
    "    \n",
    "cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = smac.Scenario(cs,\n",
    "                         walltime_limit = 30,\n",
    "                         n_trials = 5000,\n",
    "                         min_budget=1,\n",
    "                         max_budget=30,\n",
    "                         n_workers=1,\n",
    "                         seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a hyperband intensifier. Train the random forests only on the highest budget runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensifier = smac.intensifier.hyperband.Hyperband(scenario, incumbent_selection='highest_budget', seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smac_instance = smac.MultiFidelityFacade(scenario,\n",
    "                                         train,\n",
    "                                         initial_design=smac.MultiFidelityFacade.get_initial_design(scenario),\n",
    "                                         intensifier=intensifier,\n",
    "                                         overwrite=True,\n",
    "                                         logging_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_params = smac_instance.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smac_instance.validate(cs.get_default_configuration()))\n",
    "cs.get_default_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smac_instance.validate(out_params))\n",
    "out_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for t in smac_instance.intensifier.trajectory:\n",
    "    x.append(t.walltime)\n",
    "    y.append(t.costs[0])\n",
    "\n",
    "plt.plot(x, y, 'x-')\n",
    "\n",
    "baseline, = plt.plot([min(x), max(x)], [best_mse, best_mse], linestyle='--')\n",
    "\n",
    "plt.legend([baseline], ['MSE with best mixture'])\n",
    "\n",
    "plt.xlabel('Wall time')\n",
    "plt.ylabel('MSE on validation set I')\n",
    "plt.title('Each point corresponds to a bracket that led to a better incumbent')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display each bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_run(run_id):\n",
    "    print(f'SHOWING RUN {run_id}')\n",
    "\n",
    "    # Get the bracket configurations, and the total number of configurations\n",
    "    # in each run\n",
    "    bracket_sizes = intensifier._n_configs_in_stage\n",
    "    configs_per_run = sum([sum(v) for k, v in bracket_sizes.items()])\n",
    "\n",
    "    # Get all the configurations for this run\n",
    "    if len(list(smac_instance.runhistory)) < configs_per_run*run_id:\n",
    "        return False\n",
    "    \n",
    "    run_history = [smac_instance.runhistory.get_config(t.config_id)\n",
    "                        for t in list(smac_instance.runhistory)[configs_per_run*(run_id-1):][:configs_per_run]]\n",
    "\n",
    "    # Create  axes\n",
    "    rows = int(np.ceil(len(bracket_sizes)/2))\n",
    "    fig, ax = plt.subplots(rows, 2, figsize=(5*rows, 10), sharey=True)\n",
    "\n",
    "    # For each bracket, the first configurations are the unique ones (the rest are\n",
    "    # just extending the budget). Find those configurations for each budget\n",
    "    bracket_configs = {}\n",
    "    cur_config = 0\n",
    "    for bracket_n in range(len(bracket_sizes)):\n",
    "        bracket_configs[bracket_n] = run_history[cur_config:(cur_config+bracket_sizes[bracket_n][0])]\n",
    "        cur_config += sum(bracket_sizes[bracket_n])\n",
    "\n",
    "    # Plot the brackets\n",
    "    for bracket, axis in zip(bracket_configs, ax.flatten()):\n",
    "        for config in bracket_configs[bracket]:\n",
    "            weights = {i : config.get(f'w{i}') for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']}\n",
    "            weights = {i : weights[i] / sum(weights.values()) for i in weights}\n",
    "            m = trained_models[str(sorted([f'{k}:{round(v, 5)}' for k, v in weights.items()]))]\n",
    "\n",
    "            preds = np.vstack([e.predict(data['I'][['X', 'Y']].values) for e in m.estimators_])\n",
    "            preds = np.cumsum(preds, axis=0) / np.arange(1, preds.shape[0] + 1)[:, None]\n",
    "            errs = [sk_m.mean_squared_error(data['I']['Z'], p) for p in preds]\n",
    "\n",
    "            axis.plot([i + 1 for i in range(len(errs))], errs, marker='x', markersize=1, linestyle='-', linewidth=0.5, color='black')\n",
    "        \n",
    "        axis.set_title(f'Bracket {bracket}')\n",
    "\n",
    "        axis.semilogy()\n",
    "        sns.despine()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return True\n",
    "\n",
    "run_id = 1\n",
    "while show_run(run_id):\n",
    "    run_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
